{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1japvEqD2D45R5tLVwO3XvdOnxI6qNWrB","authorship_tag":"ABX9TyOx/F0kHZynTFHAHugF53mW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **UnificaciÃ³n de datasets de los niveles 1, 2, y 3**"],"metadata":{"id":"HMfeZ-nUlDtE"}},{"cell_type":"markdown","source":["En este notebook se unifican los datasets de los niveles 1, 2 y 3.\n","\n","Se fija la distribuciÃ³n de cada uno de los niveles, y se unifica el formato pra hacerlo compatible en el finetuning.\n","\n","TambiÃ©n se crean los datsets de train, test y validaciÃ³n, con una distribuciÃ³n 80/10/10, tras haber hecho un shuffle."],"metadata":{"id":"8Yk4dXlhlTjT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXm01axjfXM9"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["Afortunadamente, no hace falta instalar nuevas librerÃ­as, lo que evita las incompatibilidades."],"metadata":{"id":"acfFh4BxmRm1"}},{"cell_type":"code","source":["\"\"\"\n","UNIFICADOR FINAL PARA FINE-TUNING T5\n","Combina niveles 1, 2, 3 y prepara para entrenamiento\n","\"\"\"\n","\n","import json\n","import random\n","import pandas as pd\n","from collections import Counter\n","from typing import List, Dict, Tuple\n","import numpy as np"],"metadata":{"id":"3oP2kEm4f5k5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1C_MBzm2f5h6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["He aquÃ­ la clase que hace la unificaciÃ³n y el split de train, test, y validaciÃ³n. Estos datasets se almacenan en un directorio en Drive en el directorio dataset_t5_final."],"metadata":{"id":"WQ6vx-aNmZxl"}},{"cell_type":"code","source":["class DatasetUnifier:\n","    def __init__(self, seed=42):\n","        self.seed = seed\n","        random.seed(seed)\n","        np.random.seed(seed)\n","\n","    def load_datasets(self, paths: Dict[str, str]) -> Dict[str, List]:\n","        \"\"\"Carga datasets de los tres niveles\"\"\"\n","        datasets = {}\n","\n","        for nivel, path in paths.items():\n","            print(f\"Cargando {nivel} desde {path}...\")\n","\n","            try:\n","                # Soporte para JSONL y JSON\n","                if path.endswith('.jsonl'):\n","                    with open(path, 'r', encoding='utf-8') as f:\n","                        data = [json.loads(line) for line in f if line.strip()]\n","                elif path.endswith('.json'):\n","                    with open(path, 'r', encoding='utf-8') as f:\n","                        data = json.load(f)\n","                        if isinstance(data, dict) and \"examples\" in data:\n","                            data = data[\"examples\"]\n","                else:\n","                    raise ValueError(f\"Formato no soportado: {path}\")\n","\n","                datasets[nivel] = data\n","                print(f\"  âœ“ {len(data)} ejemplos cargados\")\n","\n","            except Exception as e:\n","                print(f\"  âœ— Error cargando {nivel}: {e}\")\n","                datasets[nivel] = []\n","\n","        return datasets\n","\n","    def unify_format(self, datasets: Dict[str, List]) -> List[Dict]:\n","        \"\"\"Unifica formato de todos los niveles\"\"\"\n","        unified = []\n","        nivel_map = {\"nivel1\": 1, \"nivel2\": 2, \"nivel3\": 3}\n","\n","        for nivel_name, ejemplos in datasets.items():\n","            for i, ej in enumerate(ejemplos):\n","                # Extraer campos (flexible para diferentes estructuras)\n","\n","                '''\n","                instruction = ej.get(\"instruction\",\n","                                   ej.get(\"pregunta\",\n","                                         ej.get(\"question\", \"\")))\n","                '''\n","\n","                instruction = ej.get(\"instruction\")\n","\n","                '''\n","                input_text = ej.get(\"input\",\n","                                  ej.get(\"contexto\",\n","                                        ej.get(\"context\", \"\")))\n","                '''\n","\n","                input_text = ej.get(\"input\")\n","\n","\n","                '''\n","                output = ej.get(\"output\",\n","                              ej.get(\"respuesta\",\n","                                    ej.get(\"answer\", \"\")))\n","\n","                '''\n","\n","                output = output = ej.get(\"output\")\n","\n","\n","\n","                # Si no hay output, saltar\n","                if not output:\n","                    continue\n","\n","                # Crear ejemplo unificado\n","                ejemplo_unificado = {\n","                    \"instruction\": instruction.strip(),\n","                    \"input\": input_text.strip() if input_text else \"\",\n","                    \"output\": output.strip(),\n","                    \"metadata\": {\n","                        **ej.get(\"metadata\", {}),\n","                        \"id\": f\"{nivel_name}_{i}\",\n","                        \"nivel_original\": nivel_name,\n","                        \"dificultad\": nivel_map.get(nivel_name, 1),\n","                        \"longitud_pregunta\": len(instruction),\n","                        \"longitud_respuesta\": len(output)\n","                    }\n","                }\n","\n","                unified.append(ejemplo_unificado)\n","\n","        print(f\"\\nğŸ“Š Total ejemplos unificados: {len(unified)}\")\n","        return unified\n","\n","    def balance_dataset(self,\n","                       unified_data: List[Dict],\n","                       target_dist: Dict[str, float] = None,\n","                       max_examples: int = 2500) -> List[Dict]:\n","        \"\"\"Balancea el dataset segÃºn distribuciÃ³n objetivo\"\"\"\n","\n","        if target_dist is None:\n","            target_dist = {\"nivel1\": 0.50, \"nivel2\": 0.35, \"nivel3\": 0.15}\n","\n","        # Agrupar por nivel\n","        by_level = {}\n","        for ej in unified_data:\n","            nivel = ej[\"metadata\"][\"nivel_original\"]\n","            if nivel not in by_level:\n","                by_level[nivel] = []\n","            by_level[nivel].append(ej)\n","\n","        print(\"\\nğŸ“ˆ DISTRIBUCIÃ“N ORIGINAL:\")\n","        for nivel, ejemplos in by_level.items():\n","            print(f\"  {nivel}: {len(ejemplos)} ejemplos\")\n","\n","        # Calcular objetivos\n","        balanced = []\n","        for nivel, ratio in target_dist.items():\n","            target_count = int(max_examples * ratio)\n","            disponibles = by_level.get(nivel, [])\n","\n","            if len(disponibles) >= target_count:\n","                selected = random.sample(disponibles, target_count)\n","            else:\n","                selected = disponibles\n","                print(f\"âš ï¸  {nivel}: Solo {len(disponibles)} disponibles \"\n","                      f\"(objetivo: {target_count})\")\n","\n","            balanced.extend(selected)\n","\n","        # Mezclar\n","        random.shuffle(balanced)\n","\n","        print(f\"\\nğŸ¯ Dataset balanceado: {len(balanced)} ejemplos\")\n","        distrib_final = Counter([e[\"metadata\"][\"nivel_original\"] for e in balanced])\n","        for nivel, count in distrib_final.items():\n","            print(f\"  {nivel}: {count} ejemplos ({count/len(balanced)*100:.1f}%)\")\n","\n","        return balanced\n","\n","    def prepare_for_t5(self,\n","                      balanced_data: List[Dict],\n","                      prompt_template: str = None) -> List[Dict]:\n","        \"\"\"Prepara datos para fine-tuning de T5\"\"\"\n","\n","        if prompt_template is None:\n","            prompt_template = (\n","                \"### InstrucciÃ³n:\\n{instruction}\\n\\n\"\n","                \"### Contexto:\\n{input}\\n\\n\"\n","                \"### Respuesta:\\n\"\n","            )\n","\n","        t5_data = []\n","\n","        for ej in balanced_data:\n","            # Construir input\n","            input_text = prompt_template.format(\n","                instruction=ej[\"instruction\"],\n","                input=ej[\"input\"] if ej[\"input\"] else \"Datos electorales espaÃ±oles\"\n","            )\n","\n","            # Target\n","            target_text = ej[\"output\"]\n","\n","            t5_example = {\n","                \"input_text\": input_text.strip(),\n","                \"target_text\": target_text.strip(),\n","                \"metadata\": ej[\"metadata\"]\n","            }\n","\n","            t5_data.append(t5_example)\n","\n","        # EstadÃ­sticas de longitud\n","        input_lens = [len(e[\"input_text\"]) for e in t5_data]\n","        target_lens = [len(e[\"target_text\"]) for e in t5_data]\n","\n","        print(f\"\\nğŸ“ ESTADÃSTICAS LONGITUD:\")\n","        print(f\"  Inputs: avg={np.mean(input_lens):.0f}, \"\n","              f\"max={max(input_lens)}, min={min(input_lens)}\")\n","        print(f\"  Targets: avg={np.mean(target_lens):.0f}, \"\n","              f\"max={max(target_lens)}, min={min(target_lens)}\")\n","\n","        return t5_data\n","\n","    def create_splits(self,\n","                     t5_data: List[Dict],\n","                     splits: Dict[str, float] = None) -> Dict[str, List]:\n","        \"\"\"Crea splits train/val/test estratificados\"\"\"\n","\n","        if splits is None:\n","            splits = {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}\n","\n","        # Estratificar por nivel\n","        by_difficulty = {}\n","        for ej in t5_data:\n","            diff = ej[\"metadata\"][\"dificultad\"]\n","            if diff not in by_difficulty:\n","                by_difficulty[diff] = []\n","            by_difficulty[diff].append(ej)\n","\n","        # Mezclar dentro de cada nivel\n","        for diff in by_difficulty:\n","            random.shuffle(by_difficulty[diff])\n","\n","        # Crear splits\n","        result = {split: [] for split in splits.keys()}\n","\n","        for diff, ejemplos in by_difficulty.items():\n","            n_total = len(ejemplos)\n","            start_idx = 0\n","\n","            for split_name, split_ratio in splits.items():\n","                n_split = int(n_total * split_ratio)\n","                end_idx = start_idx + n_split\n","\n","                result[split_name].extend(ejemplos[start_idx:end_idx])\n","                start_idx = end_idx\n","\n","        # Mezclar cada split\n","        for split_name in result:\n","            random.shuffle(result[split_name])\n","\n","        print(f\"\\nğŸ”€ SPLITS CREADOS:\")\n","        for split_name, split_data in result.items():\n","            print(f\"\\n  {split_name.upper()} ({len(split_data)} ejemplos):\")\n","\n","            # DistribuciÃ³n por nivel\n","            dist = Counter([e[\"metadata\"][\"dificultad\"] for e in split_data])\n","            for diff in sorted(dist.keys()):\n","                count = dist[diff]\n","                print(f\"    Nivel {diff}: {count} ({count/len(split_data)*100:.1f}%)\")\n","\n","        return result\n","\n","    def save_datasets(self,\n","                     splits: Dict[str, List],\n","                     output_dir: str = \"/content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_final\"):\n","        \"\"\"Guarda los splits en formato Hugging Face\"\"\"\n","\n","        import os\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","        # Guardar en mÃºltiples formatos\n","        for split_name, split_data in splits.items():\n","            # JSONL (para Hugging Face)\n","            jsonl_path = f\"{output_dir}/{split_name}.jsonl\"\n","            with open(jsonl_path, 'w', encoding='utf-8') as f:\n","                for ejemplo in split_data:\n","                    f.write(json.dumps(ejemplo, ensure_ascii=False) + '\\n')\n","\n","            # CSV (para inspecciÃ³n)\n","            csv_path = f\"{output_dir}/{split_name}.csv\"\n","            df = pd.DataFrame([\n","                {\n","                    \"input\": e[\"input_text\"],\n","                    \"target\": e[\"target_text\"],\n","                    \"dificultad\": e[\"metadata\"][\"dificultad\"],\n","                    \"nivel\": e[\"metadata\"][\"nivel_original\"]\n","                }\n","                for e in split_data\n","            ])\n","            df.to_csv(csv_path, index=False, encoding='utf-8')\n","\n","            print(f\"  ğŸ’¾ {split_name}: {len(split_data)} ejemplos -> {jsonl_path}\")\n","\n","        # Guardar metadata\n","        metadata = {\n","            \"total_examples\": sum(len(s) for s in splits.values()),\n","            \"split_sizes\": {k: len(v) for k, v in splits.items()},\n","            \"creation_date\": pd.Timestamp.now().isoformat(),\n","            \"seed\": self.seed,\n","            \"description\": \"Dataset electoral espaÃ±ol para fine-tuning T5\"\n","        }\n","\n","        with open(f\"{output_dir}/metadata.json\", 'w') as f:\n","            json.dump(metadata, f, indent=2)\n","\n","        print(f\"\\nâœ… Dataset guardado en: {output_dir}\")\n","\n","        return output_dir"],"metadata":{"id":"DQEQdNpMf5fJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dkLCOOyqf5ca"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esta es la funciÃ³n main(), en el que declaramos los paths a los datasets de los niveles, y que activa los mÃ©todos de la clase que realiza la unificaciÃ³n."],"metadata":{"id":"kYAWsUB-nLkI"}},{"cell_type":"code","source":["def main():\n","    \"\"\"Pipeline completo de unificaciÃ³n\"\"\"\n","\n","    # CONFIGURACIÃ“N\n","    PATHS = {\n","        \"nivel1\": \"/content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_preguntas_nivel1.jsonl\",\n","        \"nivel2\": \"/content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_preguntas_nivel2.jsonl\",\n","        \"nivel3\": \"/content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_nivel3.jsonl\"\n","    }\n","\n","    # 1. Inicializar unificador\n","    unifier = DatasetUnifier(seed=42)\n","\n","    # 2. Cargar datasets\n","    datasets = unifier.load_datasets(PATHS)\n","\n","    # 3. Unificar formato\n","    unified = unifier.unify_format(datasets)\n","\n","    # 4. Balancear (2000 ejemplos total)\n","    balanced = unifier.balance_dataset(\n","        unified,\n","        target_dist={\"nivel1\": 0.50, \"nivel2\": 0.35, \"nivel3\": 0.15},\n","        max_examples=2000\n","    )\n","\n","    # 5. Preparar para T5\n","    t5_data = unifier.prepare_for_t5(balanced)\n","\n","    # 6. Crear splits\n","    splits = unifier.create_splits(\n","        t5_data,\n","        splits={\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}\n","    )\n","\n","    # 7. Guardar\n","    output_dir = unifier.save_datasets(splits, \"/content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_t5_final\")\n","\n","    print(f\"\\nğŸ‰ PROCESO COMPLETADO!\")\n","    print(f\"ğŸ“ Dataset listo para fine-tuning en: {output_dir}\")\n","\n","    return splits\n"],"metadata":{"id":"TWc-uwgOf5ZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RgFnGk-4gG_q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comenzamos la unificaciÃ³n, y vemos que se realiza correctamente."],"metadata":{"id":"guYsvPgQnhif"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    splits = main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tr7SYmblgG0S","executionInfo":{"status":"ok","timestamp":1769686894542,"user_tz":-60,"elapsed":1232,"user":{"displayName":"Guillermo Barrio","userId":"06925154007558381895"}},"outputId":"3ad0dd2a-b9eb-4445-c0d5-a7057aa184ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cargando nivel1 desde /content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_preguntas_nivel1.jsonl...\n","  âœ“ 2000 ejemplos cargados\n","Cargando nivel2 desde /content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_preguntas_nivel2.jsonl...\n","  âœ“ 600 ejemplos cargados\n","Cargando nivel3 desde /content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_nivel3.jsonl...\n","  âœ“ 200 ejemplos cargados\n","\n","ğŸ“Š Total ejemplos unificados: 2800\n","\n","ğŸ“ˆ DISTRIBUCIÃ“N ORIGINAL:\n","  nivel1: 2000 ejemplos\n","  nivel2: 600 ejemplos\n","  nivel3: 200 ejemplos\n","âš ï¸  nivel2: Solo 600 disponibles (objetivo: 700)\n","âš ï¸  nivel3: Solo 200 disponibles (objetivo: 300)\n","\n","ğŸ¯ Dataset balanceado: 1800 ejemplos\n","  nivel2: 600 ejemplos (33.3%)\n","  nivel3: 200 ejemplos (11.1%)\n","  nivel1: 1000 ejemplos (55.6%)\n","\n","ğŸ“ ESTADÃSTICAS LONGITUD:\n","  Inputs: avg=246, max=1064, min=141\n","  Targets: avg=507, max=5182, min=65\n","\n","ğŸ”€ SPLITS CREADOS:\n","\n","  TRAIN (1440 ejemplos):\n","    Nivel 1: 800 (55.6%)\n","    Nivel 2: 480 (33.3%)\n","    Nivel 3: 160 (11.1%)\n","\n","  VAL (180 ejemplos):\n","    Nivel 1: 100 (55.6%)\n","    Nivel 2: 60 (33.3%)\n","    Nivel 3: 20 (11.1%)\n","\n","  TEST (180 ejemplos):\n","    Nivel 1: 100 (55.6%)\n","    Nivel 2: 60 (33.3%)\n","    Nivel 3: 20 (11.1%)\n","  ğŸ’¾ train: 1440 ejemplos -> /content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_t5_final/train.jsonl\n","  ğŸ’¾ val: 180 ejemplos -> /content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_t5_final/val.jsonl\n","  ğŸ’¾ test: 180 ejemplos -> /content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_t5_final/test.jsonl\n","\n","âœ… Dataset guardado en: /content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_t5_final\n","\n","ğŸ‰ PROCESO COMPLETADO!\n","ğŸ“ Dataset listo para fine-tuning en: /content/drive/MyDrive/Practica_LLM_Engineering_25/dataset_t5_final\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"T-2MGFVPf5V5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sagXMI5Pf5RJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q29CXx_jf5Ha"},"execution_count":null,"outputs":[]}]}